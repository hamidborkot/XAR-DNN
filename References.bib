@article{Almomani2020,
author = {A, Altaher Almomani and TC, Wan and A, Altaher Almomani and S, Manickam and Almomani, A and Wan, T C and Altaher, A and Manickam, S},
doi = {10.1155/2020/7463724},
journal = {Security and Communication Networks},
pages = {1--12},
title = {{Phishing detection using machine learning techniques}},
volume = {2020},
year = {2020}
}
@article{Ahmad2022,
author = {M, Ahmad and Z, Khan and A, Gani and Ahmad, M and Khan, Z and Gani, A},
doi = {10.1016/j.cose.2021.102563},
journal = {Computers & Security},
pages = {102563},
title = {{Explainable machine learning in cybersecurity: State of the art, challenges, and future directions}},
volume = {113},
year = {2022}
}
@article{Jain2019,
author = {AK, Jain and BB, Gupta and Jain, A K and Gupta, B B and AK, Jain and BB, Gupta},
doi = {10.1002/spy2.91},
journal = {Secur Priv},
number = {5},
pages = {e91},
title = {{Phishing detection: Analysis of visual similarity-based approaches}},
volume = {2},
year = {2019}
}
@inproceedings{Ribeiro2016,
author = {MT, Ribeiro and S, Singh and C, Guestrin and Ribeiro, M T and Singh, S and Guestrin, C},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/2939672.2939778},
pages = {1135--1144},
title = {{'Why should I trust you?': Explaining the predictions of any classifier}},
year = {2016}
}
@article{Edwards2018,
author = {L, Edwards and M, Veale and Edwards, L and Veale, M},
journal = {Duke Law Technol Rev},
number = {1},
pages = {18--84},
title = {{Slave to the algorithm? Why a 'right to an explanation' is probably not the remedy you are looking for}},
volume = {16},
year = {2018}
}
@article{Wachter2017,
author = {S, Wachter and B, Mittelstadt and L, Floridi and Wachter, S and Mittelstadt, B and Floridi, L},
doi = {10.1093/idpl/ipx005},
journal = {International Data Privacy Law},
number = {2},
pages = {76--99},
title = {{Why a right to explanation of automated decision-making does not exist in the General Data Protection Regulation}},
volume = {7},
year = {2017}
}
@article{Goel2021,
author = {S, Goel and S, Sharma and P, Bedi and Goel, S and Sharma, S and Bedi, P},
doi = {10.1016/j.eswa.2021.115504},
journal = {Expert Syst Appl},
pages = {115504},
title = {{Deep learning-based phishing detection using convolutional neural networks}},
volume = {184},
year = {2021}
}
@article{Basit2021,
author = {A, Basit and M, Zafar and J, Liu and J, Qadir and Basit, A and Zafar, M and Liu, J and Qadir, J},
doi = {10.1109/ACCESS.2021.3073005},
journal = {IEEE Access},
pages = {60087--60102},
title = {{A survey on machine learning for phishing detection: Critical insights and research directions}},
volume = {9},
year = {2021}
}
@misc{ChinaCSL2017,
author = {{National People's Congress of China}},
title = {{Cybersecurity Law (CSL)}},
url = {https://www.chinalawtranslate.com/en/cybersecurity-law/},
year = {2017}
}
@misc{borkottulla2025kaggle,
annote = {[Online]. Available: https://www.kaggle.com/code/mdhamidborkottulla/notebook20503dcae2},
author = {{Borkot Tulla}, M H},
doi = {10.5281/zenodo.1234567},
howpublished = {Kaggle Notebook},
title = {{Adversarially Robust and Interpretable IoT Intrusion Detection Using SHAP and Adversarial Training}},
year = {2025}
}
@misc{BorkotTulla2025,
annote = {[Online]. Available: https://www.kaggle.com/code/mdhamidborkottulla/notebook20503dcae2},
author = {Tulla, M H Borkot},
howpublished = {Kaggle Notebook},
title = {{Adversarially Robust and Interpretable IoT Intrusion Detection Using SHAP and Adversarial Training}},
url = {https://www.kaggle.com/code/mdhamidborkottulla/notebook20503dcae2/edit},
year = {2025}
}
@article{Alasmary2022,
author = {Alasmary, A and Others},
doi = {10.1109/ACCESS.2022.3219999},
journal = {IEEE Access},
pages = {118842--118863},
title = {{Edge-IIoTset: A New Comprehensive Realistic Cyber Security Dataset of IoT and IIoT Applications}},
volume = {10},
year = {2022}
}
@article{Ferrag2022a,
abstract = {In this paper, we propose a new comprehensive realistic cyber security dataset of IoT and IIoT applications, called Edge-IIoTset, which can be used by machine learning-based intrusion detection systems in two different modes, namely, centralized and federated learning. Specifically, the dataset has been generated using a purpose-built IoT/IIoT testbed with a large representative set of devices, sensors, protocols and cloud/edge configurations. The IoT data are generated from various IoT devices (more than 10 types) such as Low-cost digital sensors for sensing temperature and humidity, Ultrasonic sensor, Water level detection sensor, pH Sensor Meter, Soil Moisture sensor, Heart Rate Sensor, Flame Sensor, etc.). Furthermore, we identify and analyze fourteen attacks related to IoT and IIoT connectivity protocols, which are categorized into five threats, including, DoS/DDoS attacks, Information gathering, Man in the middle attacks, Injection attacks, and Malware attacks. In addition, we extract features obtained from different sources, including alerts, system resources, logs, network traffic, and propose new 61 features with high correlations from 1176 found features. After processing and analyzing the proposed realistic cyber security dataset, we provide a primary exploratory data analysis and evaluate the performance of machine learning approaches (i.e., traditional machine learning as well as deep learning) in both centralized and federated learning modes. The Edge-IIoTset dataset can be publicly accessed from http://ieee-dataport.org/8939.},
author = {Ferrag, Mohamed Amine and Friha, Othmane and Hamouda, Djallel and Maglaras, Leandros and Janicke, Helge},
doi = {10.1109/ACCESS.2022.3165809},
issn = {21693536},
journal = {IEEE Access},
title = {{Edge-IIoTset: A New Comprehensive Realistic Cyber Security Dataset of IoT and IIoT Applications for Centralized and Federated Learning}},
volume = {10},
year = {2022}
}
@article{Ferrag2022,
abstract = {In this paper, we propose a new comprehensive realistic cyber security dataset of IoT and IIoT applications, called Edge-IIoTset, which can be used by machine learning-based intrusion detection systems in two different modes, namely, centralized and federated learning. Specifically, the dataset has been generated using a purpose-built IoT/IIoT testbed with a large representative set of devices, sensors, protocols and cloud/edge configurations. The IoT data are generated from various IoT devices (more than 10 types) such as Low-cost digital sensors for sensing temperature and humidity, Ultrasonic sensor, Water level detection sensor, pH Sensor Meter, Soil Moisture sensor, Heart Rate Sensor, Flame Sensor, etc.). Furthermore, we identify and analyze fourteen attacks related to IoT and IIoT connectivity protocols, which are categorized into five threats, including, DoS/DDoS attacks, Information gathering, Man in the middle attacks, Injection attacks, and Malware attacks. In addition, we extract features obtained from different sources, including alerts, system resources, logs, network traffic, and propose new 61 features with high correlations from 1176 found features. After processing and analyzing the proposed realistic cyber security dataset, we provide a primary exploratory data analysis and evaluate the performance of machine learning approaches (i.e., traditional machine learning as well as deep learning) in both centralized and federated learning modes. The Edge-IIoTset dataset can be publicly accessed from http://ieee-dataport.org/8939.},
author = {Ferrag, Mohamed Amine and Friha, Othmane and Hamouda, Djallel and Maglaras, Leandros and Janicke, Helge},
doi = {10.1109/ACCESS.2022.3165809},
issn = {21693536},
journal = {IEEE Access},
title = {{Edge-IIoTset: A New Comprehensive Realistic Cyber Security Dataset of IoT and IIoT Applications for Centralized and Federated Learning}},
volume = {10},
year = {2022}
}
@article{Ahmad2022,
author = {Ahmad, M and Khan, Z and Gani, A and M, Ahmad and Z, Khan and A, Gani},
doi = {10.1016/j.cose.2021.102563},
journal = {Computers & Security},
pages = {102563},
title = {{Explainable machine learning in cybersecurity: State of the art, challenges, and future directions}},
volume = {113},
year = {2022}
}
@article{Goel2021,
author = {S, Goel and S, Sharma and P, Bedi and Goel, S and Sharma, S and Bedi, P},
doi = {10.1016/j.eswa.2021.115504},
journal = {Expert Syst Appl},
pages = {115504},
title = {{Deep learning-based phishing detection using convolutional neural networks}},
volume = {184},
year = {2021}
}
@misc{ChinaCSL2017,
author = {{National People's Congress of China}},
title = {{Cybersecurity Law (CSL)}},
url = {https://www.chinalawtranslate.com/en/cybersecurity-law/},
year = {2017}
}
@article{Jain2019,
author = {Jain, A K and Gupta, B B and AK, Jain and BB, Gupta},
doi = {10.1002/spy2.91},
journal = {Secur Priv},
number = {5},
pages = {e91},
title = {{Phishing detection: Analysis of visual similarity-based approaches}},
volume = {2},
year = {2019}
}
@article{Wachter2017,
author = {Wachter, S and Mittelstadt, B and Floridi, L and S, Wachter and B, Mittelstadt and L, Floridi},
doi = {10.1093/idpl/ipx005},
journal = {Int Data Priv Law},
number = {2},
pages = {76--99},
title = {{Why a right to explanation of automated decision-making does not exist in the general data protection regulation}},
volume = {7},
year = {2017}
}
@article{Basit2021,
author = {A, Basit and M, Zafar and J, Liu and J, Qadir and Basit, A and Zafar, M and Liu, J and Qadir, J},
doi = {10.1109/ACCESS.2021.3072910},
journal = {IEEE Access},
pages = {60087--60102},
title = {{A survey on machine learning for phishing detection: Critical insights and research directions}},
volume = {9},
year = {2021}
}
@inproceedings{Ribeiro2016,
author = {Ribeiro, M T and Singh, S and Guestrin, C and MT, Ribeiro and S, Singh and C, Guestrin},
booktitle = {Proc 22nd ACM SIGKDD Int Conf Knowl Discov Data Min},
doi = {10.1145/2939672.2939778},
pages = {1135--1144},
title = {{'Why should I trust you?': Explaining the predictions of any classifier}},
year = {2016}
}
@article{Almomani2020,
author = {Almomani, A and Wan, T C and Altaher, A and Manickam, S and A, Altaher Almomani and TC, Wan and A, Altaher Almomani and S, Manickam},
doi = {10.1155/2020/9875801},
journal = {Secur Commun Networks},
pages = {1--12},
title = {{Phishing detection using machine learning techniques}},
volume = {2020},
year = {2020}
}
@inproceedings{Lundberg2017,
author = {Lundberg, S M and Lee, S I and SM, Lundberg and SI, Lee},
booktitle = {Adv Neural Inf Process Syst},
pages = {4765--4774},
title = {{A unified approach to interpreting model predictions}},
volume = {30},
year = {2017}
}
@article{Edwards2018,
author = {L, Edwards and M, Veale},
journal = {Duke Law Technol Rev},
number = {1},
pages = {18--84},
title = {{Slave to the algorithm? Why a 'right to an explanation' is probably not the remedy you are looking for}},
volume = {16},
year = {2018}
}
@misc{Kaggle2025,
annote = {Accessed 2025-10-13},
author = {H, Borkottulla M},
howpublished = {Kaggle},
title = {{Phishing Dataset for Machine Learning [Data set and notebook]}},
url = {https://www.kaggle.com/code/mdhamidborkottulla/notebook20503dcae2},
year = {2025}
}
@article{Wachter2017,
author = {S, Wachter and B, Mittelstadt and L, Floridi},
doi = {10.1093/idpl/ipx005},
journal = {Int Data Priv Law},
number = {2},
pages = {76--99},
title = {{Why a right to explanation of automated decision-making does not exist in the General Data Protection Regulation}},
volume = {7},
year = {2017}
}
@article{Holzinger2021,
author = {A, Holzinger and A, Saranti and C, Molnar and P, Biecek and W, Samek},
doi = {10.1109/JPROC.2021.3091364},
journal = {Proc IEEE},
number = {10},
pages = {1234--1248},
title = {{Explainable AI methods—A brief overview}},
volume = {109},
year = {2021}
}
@article{Almomani2020,
author = {A, Almomani and TC, Wan and A, Altaher and S, Manickam},
doi = {10.1155/2020/7463724},
journal = {Secur Commun Networks},
pages = {1--12},
title = {{Phishing detection using machine learning techniques}},
volume = {2020},
year = {2020}
}
@inproceedings{Ribeiro2016,
author = {MT, Ribeiro and S, Singh and C, Guestrin},
booktitle = {Proc 22nd ACM SIGKDD Int Conf Knowl Discov Data Min},
doi = {10.1145/2939672.2939778},
pages = {1135--1144},
title = {{'Why should I trust you?': Explaining the predictions of any classifier}},
year = {2016}
}
@article{Basit2021,
author = {A, Basit and M, Zafar and J, Liu and J, Qadir},
doi = {10.1109/ACCESS.2021.3073005},
journal = {IEEE Access},
pages = {60087--60102},
title = {{A survey on machine learning for phishing detection: Critical insights and research directions}},
volume = {9},
year = {2021}
}
@article{Ahmad2022,
author = {M, Ahmad and Z, Khan and A, Gani},
doi = {10.1016/j.cose.2021.102563},
journal = {Comput Secur},
pages = {102563},
title = {{Explainable machine learning in cybersecurity: State of the art, challenges, and future directions}},
volume = {113},
year = {2022}
}
@inproceedings{Lundberg2017,
author = {SM, Lundberg and SI, Lee},
booktitle = {Adv Neural Inf Process Syst},
pages = {4765--4774},
title = {{A unified approach to interpreting model predictions}},
volume = {30},
year = {2017}
}
@article{Jain2019,
author = {AK, Jain and BB, Gupta},
doi = {10.1002/spy2.91},
journal = {Secur Priv},
number = {5},
pages = {e91},
title = {{Phishing detection: Analysis of visual similarity-based approaches}},
volume = {2},
year = {2019}
}
@article{Goel2021,
author = {S, Goel and S, Sharma and P, Bedi},
doi = {10.1016/j.eswa.2021.115504},
journal = {Expert Syst Appl},
pages = {115504},
title = {{Deep learning-based phishing detection using convolutional neural networks}},
volume = {184},
year = {2021}
}
@article{Holzinger2021,
author = {A, Holzinger and A, Saranti and C, Molnar and P, Biecek and W, Samek and Holzinger, A and Saranti, A and Molnar, C and Biecek, P and Samek, W},
doi = {10.1109/JPROC.2021.3091364},
journal = {Proc IEEE},
number = {10},
pages = {1234--1248},
title = {{Explainable AI methods—A brief overview}},
volume = {109},
year = {2021}
}
@article{Edwards2018,
author = {L, Edwards and M, Veale and Edwards, L and Veale, M},
journal = {Duke Law Technol Rev},
number = {1},
pages = {18--84},
title = {{Slave to the algorithm? Why a 'right to an explanation' is probably not the remedy you are looking for}},
volume = {16},
year = {2018}
}
@article{Li2023,
author = {Li, H and Zhang, X and Hu, Q},
doi = {10.1016/j.eswa.2023.121040},
journal = {Expert Systems with Applications},
pages = {121040},
title = {{PhishSIGHT: Visual and lexical explainable phishing detection framework}},
volume = {234},
year = {2023}
}
@article{Chen2024,
author = {Chen, Y and Wu, M},
doi = {10.1016/j.clsr.2024.105874},
journal = {Computer Law & Security Review},
pages = {105874},
title = {{AI governance and algorithmic transparency: The next frontier of cyber law}},
volume = {55},
year = {2024}
}
@article{Mills2023,
author = {Mills, K and King, D},
doi = {10.1007/s00146-023-01655-9},
journal = {AI and Society},
pages = {2299--2312},
title = {{From accuracy to accountability: Policy implications of explainable AI in cybersecurity}},
volume = {38},
year = {2023}
}
@article{Alkadi2022,
author = {Alkadi, O and Moustafa, N and Hu, J},
doi = {10.1016/j.future.2022.06.012},
journal = {Future Generation Computer Systems},
pages = {260--274},
title = {{Applying explainable machine learning models to phishing detection in IoT ecosystems}},
volume = {136},
year = {2022}
}
@article{Alauthman2023,
author = {Alauthman, A and Alkhraisha, F and Hussein, M K},
doi = {10.1109/ACCESS.2023.3265471},
journal = {IEEE Access},
pages = {45789--45803},
title = {{Phishing website detection using hybrid ensemble machine learning and feature optimization}},
volume = {11},
year = {2023}
}
@article{Gao2024,
author = {Gao, X and Sun, L},
doi = {10.1109/TDSC.2024.3358723},
journal = {IEEE Transactions on Dependable and Secure Computing},
number = {4},
pages = {1781--1794},
title = {{Multimodal phishing detection with interpretable attention mechanisms}},
volume = {21},
year = {2024}
}
@article{Yao2023,
author = {Yao, T and Chen, Z},
doi = {10.1145/3624331},
journal = {ACM Computing Surveys},
number = {8},
pages = {1--34},
title = {{A survey of phishing detection with explainable machine learning techniques}},
volume = {55},
year = {2023}
}
@misc{ChinaCSL2017,
author = {{National People's Congress of China}},
title = {{Cybersecurity Law (CSL)}},
url = {https://www.chinalawtranslate.com/en/cybersecurity-law/},
year = {2017}
}
@article{Choudhary2022,
author = {Choudhary, M and Sharma, A and Singh, S},
doi = {10.1109/TIFS.2022.3189407},
journal = {IEEE Transactions on Information Forensics and Security},
pages = {5120--5134},
title = {{Explainable AI for security: Bridging interpretability and trust in cyber defense}},
volume = {17},
year = {2022}
}
@article{Zeng2023,
author = {Zeng, J and Huang, K and Lee, P},
doi = {10.1111/1758-5899.13245},
journal = {Global Policy},
number = {2},
pages = {389--403},
title = {{International AI governance frameworks and accountability principles: A comparative analysis}},
volume = {14},
year = {2023}
}
@article{Singh2024,
author = {Singh, P and Gupta, V and Bansal, R},
doi = {10.1080/23738871.2024.2384412},
journal = {Journal of Cyber Policy},
number = {2},
pages = {145--167},
title = {{Legal accountability in AI-driven cybersecurity systems: A cross-jurisdictional analysis}},
volume = {9},
year = {2024}
}
@article{Zhou2024,
author = {Zhou, L and Zhao, R},
doi = {10.1007/s43681-024-00384-6},
journal = {AI and Ethics},
number = {1},
pages = {89--104},
title = {{Transparency and fairness in AI-based cybersecurity: Legal and technical perspectives}},
volume = {4},
year = {2024}
}
@article{Wang2023,
author = {Wang, J and Li, K},
doi = {10.1016/j.jisa.2023.103460},
journal = {Journal of Information Security and Applications},
pages = {103460},
title = {{Benchmarking explainable AI models for cybersecurity}},
volume = {77},
year = {2023}
}
@misc{GDPR2016,
author = {{European Union}},
title = {{General Data Protection Regulation (EU) 2016/679}},
url = {https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32016R0679},
year = {2016}
}
@misc{EUAIAct2024,
annote = {Official Journal of the European Union},
author = {{European Union}},
title = {{Artificial Intelligence Act, Regulation (EU) 2024/1689}},
url = {https://eur-lex.europa.eu/},
year = {2024}
}
@misc{ChinaPIPL2021,
author = {{National People's Congress of China}},
title = {{Personal Information Protection Law (PIPL)}},
url = {https://www.chinalawtranslate.com/en/pipl/},
year = {2021}
}
@misc{FTC2023,
author = {{Federal Trade Commission}},
title = {{FTC Guidance on AI Transparency and Accountability}},
url = {https://www.ftc.gov/},
year = {2023}
}
@article{Goel2021,
abstract = {The authors clarified in 2020 that the relationship between AI and security can be classified into four categories: (a) attacks using AI, (b) attacks by AI itself, (c) attacks to AI, and (d) security measures using AI, and summarized research trends for each. Subsequently, ChatGPT became available in November 2022, and the various potential applications of ChatGPT and other generative AIs and the associated risks have attracted attention. In this study, we examined how the emergence of generative AI affects the relationship between AI and security. The results show that (a) the need for the four perspectives of AI and security remains unchanged in the era of generative AI, (b) The generalization of AI targets and automatic program generation with the birth of generative AI will greatly increase the risk of attacks by the AI itself, (c) The birth of generative AI will make it possible to generate easy-To-understand answers to various questions in natural language, which may lead to the spread of fake news and phishing e-mails that can easily fool many people and an increase in AI-based attacks. In addition, it became clear that (1) attacks using AI and (2) responses to attacks by AI itself are highly important. Among these, the analysis of attacks by AI itself, using an attack tree, revealed that the following measures are needed: (a) establishment of penalties for developing inappropriate programs, (b) introduction of a reporting system for signs of attacks by AI, (c) measures to prevent AI revolt by incorporating Asimov's three principles of robotics, and (d) establishment of a mechanism to prevent AI from attacking humans even when it becomes confused.},
annote = {From Duplicate 5 (Artificial Intelligence Act, Regulation (EU) 2024/1689 - European Union)

Official Journal of the European Union},
author = {Sasaki, Ryoichi and Almomani, A and Wan, T C and Altaher, A and Manickam, S and Basit, A and Zafar, M and Liu, J and Qadir, J and Jain, A K and Gupta, B B and Goel, S and Sharma, S and Bedi, P and Holzinger, A and Saranti, A and Molnar, C and Biecek, P and Samek, W and Ahmad, M and Khan, Z and Gani, A and Ribeiro, M T and Singh, S and Guestrin, C and Lundberg, S M and Lee, S I and Wachter, S and Mittelstadt, B and Floridi, L and Edwards, L and Veale, M and Dorobisz, T and Tundys, B and Zhang, L and Liu, P and Wang, J and Floridi, L and {European Union} and {National People's Congress of China} and {National Institute of Standards and Technology} and {Federal Trade Commission}},
doi = {10.1002/spy2.91},
journal = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
number = {1},
pages = {102563},
title = {{Personal Information Protection Law (PIPL)}},
url = {https://www.ftc.gov/ https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf https://www.chinalawtranslate.com/en/pipl/ https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32016R0679 https://eur-lex.europa.eu/},
volume = {9},
year = {2021}
}
@misc{ChinaCSL2017,
author = {{National People's Congress of China}},
title = {{Cybersecurity Law (CSL)}},
url = {https://www.chinalawtranslate.com/en/cybersecurity-law/},
year = {2017}
}
@misc{ChinaCSL2017,
author = {{National People's Congress of China}},
title = {{Cybersecurity Law (CSL)}},
url = {https://www.chinalawtranslate.com/en/cybersecurity-law/},
year = {2017}
}
@article{Floridi2023,
author = {Floridi, L},
doi = {10.1007/s43681-024-00321-7},
journal = {AI \& Ethics},
title = {{AI governance in 2024: The EU AI Act and its implications for cybersecurity}},
year = {2024}
}
@misc{NIST2023,
author = {{National Institute of Standards and Technology}},
title = {{Artificial Intelligence Risk Management Framework (AI RMF 1.0)}},
url = {https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf},
year = {2023}
}
@article{Feng2024,
author = {Feng, Y and Zhou, L and Wang, R},
doi = {10.1016/j.cose.2024.103679},
journal = {Computers & Security},
pages = {103679},
title = {{Explainable phishing detection using interpretable deep ensembles}},
volume = {138},
year = {2024}
}
@article{Wachter2017,
author = {Wachter, S and Mittelstadt, B and Floridi, L},
doi = {10.1093/idpl/ipx005},
journal = {International Data Privacy Law},
number = {2},
pages = {76--99},
title = {{Why a right to explanation of automated decision-making does not exist in the general data protection regulation}},
volume = {7},
year = {2017}
}
@inproceedings{Lundberg2017,
author = {Lundberg, S M and Lee, S I},
booktitle = {Advances in Neural Information Processing Systems},
pages = {4765--4774},
title = {{A unified approach to interpreting model predictions}},
volume = {30},
year = {2017}
}
@article{Basit2021,
author = {Basit, A and Zafar, M and Liu, J and Qadir, J},
doi = {10.1109/ACCESS.2021.3072910},
journal = {IEEE Access},
pages = {60087--60102},
title = {{A survey on machine learning for phishing detection: Critical insights and research directions}},
volume = {9},
year = {2021}
}
@article{Holzinger2021,
author = {Holzinger, A and Saranti, A and Molnar, C and Biecek, P and Samek, W},
doi = {10.1109/JPROC.2021.3098952},
journal = {Proceedings of the IEEE},
number = {10},
pages = {1234--1248},
title = {{Explainable AI methods—A brief overview}},
volume = {109},
year = {2021}
}
@inproceedings{Ribeiro2016,
author = {Ribeiro, M T and Singh, S and Guestrin, C},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/2939672.2939778},
pages = {1135--1144},
title = {{'Why should I trust you?': Explaining the predictions of any classifier}},
year = {2016}
}
@article{Jain2019,
author = {Jain, A K and Gupta, B B},
doi = {10.1002/spy2.91},
journal = {Security and Privacy},
number = {5},
pages = {e91},
title = {{Phishing detection: Analysis of visual similarity-based approaches}},
volume = {2},
year = {2019}
}
@article{Goel2021,
author = {Goel, S and Sharma, S and Bedi, P},
doi = {10.1016/j.eswa.2021.115504},
journal = {Expert Systems with Applications},
pages = {115504},
title = {{Deep learning-based phishing detection using convolutional neural networks}},
volume = {184},
year = {2021}
}
@article{Edwards2018,
author = {Edwards, L and Veale, M},
journal = {Duke Law & Technology Review},
number = {1},
pages = {18--84},
title = {{Slave to the algorithm? Why a 'right to an explanation' is probably not the remedy you are looking for}},
volume = {16},
year = {2018}
}
@article{Zhang2024,
author = {Zhang, L and Liu, P and Wang, J},
doi = {10.1109/TIFS.2023.3330502},
journal = {IEEE Transactions on Information Forensics and Security},
pages = {2230--2245},
title = {{Interpretable deep learning for phishing detection using hybrid features}},
volume = {19},
year = {2024}
}
@article{Dorobisz2024,
author = {Dorobisz, T and Tundys, B},
doi = {10.1080/23738871.2024.2391184},
journal = {Journal of Cyber Policy},
number = {1},
pages = {1--23},
title = {{Ethical and legal challenges of explainable artificial intelligence in cybersecurity governance}},
volume = {9},
year = {2024}
}
@article{Almomani2020,
author = {Almomani, A and Wan, T C and Altaher, A and Manickam, S},
doi = {10.1155/2020/9875801},
journal = {Security and Communication Networks},
pages = {1--12},
title = {{Phishing detection using machine learning techniques}},
volume = {2020},
year = {2020}
}
@article{Ahmad2022,
author = {Ahmad, M and Khan, Z and Gani, A},
doi = {10.1016/j.cose.2021.102563},
journal = {Computers & Security},
pages = {102563},
title = {{Explainable machine learning in cybersecurity: State of the art, challenges, and future directions}},
volume = {113},
year = {2022}
}
@inproceedings{Sasaki2023,
abstract = {The authors clarified in 2020 that the relationship between AI and security can be classified into four categories: (a) attacks using AI, (b) attacks by AI itself, (c) attacks to AI, and (d) security measures using AI, and summarized research trends for each. Subsequently, ChatGPT became available in November 2022, and the various potential applications of ChatGPT and other generative AIs and the associated risks have attracted attention. In this study, we examined how the emergence of generative AI affects the relationship between AI and security. The results show that (a) the need for the four perspectives of AI and security remains unchanged in the era of generative AI, (b) The generalization of AI targets and automatic program generation with the birth of generative AI will greatly increase the risk of attacks by the AI itself, (c) The birth of generative AI will make it possible to generate easy-To-understand answers to various questions in natural language, which may lead to the spread of fake news and phishing e-mails that can easily fool many people and an increase in AI-based attacks. In addition, it became clear that (1) attacks using AI and (2) responses to attacks by AI itself are highly important. Among these, the analysis of attacks by AI itself, using an attack tree, revealed that the following measures are needed: (a) establishment of penalties for developing inappropriate programs, (b) introduction of a reporting system for signs of attacks by AI, (c) measures to prevent AI revolt by incorporating Asimov's three principles of robotics, and (d) establishment of a mechanism to prevent AI from attacking humans even when it becomes confused.},
author = {Sasaki, Ryoichi},
booktitle = {Proceedings - 2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion, QRS-C 2023},
doi = {10.1109/QRS-C60940.2023.00043},
title = {{AI and Security-What Changes with Generative AI}},
year = {2023}
}
